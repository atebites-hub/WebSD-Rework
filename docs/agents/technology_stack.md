# Technology Stack — Web Stable Diffusion (Rework)

This document defines the end-to-end stack to run Stable Diffusion entirely in the browser using WebGPU with models compiled by Apache TVM v0.21.0. It also captures compatibility constraints and integration points so implementation and testing can proceed with minimal ambiguity.

## Goals
- Run SD 1.5 and SDXL in modern browsers with WebGPU acceleration.
- Compile models from PyTorch to TVM (Relax → TensorIR → MetaSchedule) and deploy as WebAssembly + WebGPU shaders via tvmjs.
- Keep the Python toolchain forward-compatible while respecting third-party library support constraints.

## Core Components

- Python
  - Preferred: Python 3.13 (forward-compat target for this project; do not target 3.14).
  - Practical build baseline: Python 3.13; ensure tooling and CI use Python 3.13 to remain compatible with PyTorch 2.7.

- PyTorch
  - Target: PyTorch 2.7 (aligned with TVM CI upgrades).
  - Role: Model authoring and graph capture (TorchDynamo / FX) feeding TVM’s Relax frontend.

- Apache TVM
  - Version: v0.21.0.
  - Role: Compile the SD components (CLIP, UNet, VAE, schedulers) into deployable modules for WebGPU.
  - Notables in v0.21: FFI refactor, web runtime upgrade, relax_vm → vm rename, minimum Python now 3.9+. See References.

- tvmjs (Web runtime)
  - Artifacts: `tvmjs_runtime.wasi.js`, `tvmjs.bundle.js`, model `.wasm` produced by TVM, and NDArray parameter shards.
  - Key APIs used: `tvmjs.instantiate`, `tvm.initWebGPU`, `tvm.createVirtualMachine`, `vm.getFunction`, `tvm.getParamsFromCache`, `tvm.fetchNDArrayCache`, `tvm.asyncLoadWebGPUPipelines`.
  - Execution device: WebGPU.

- WebGPU
  - Role: GPU execution in browser for kernels generated by TVM (WGSL shaders) and orchestrated by tvmjs.
  - Browser scope: “Modern browsers that support WebGPU.” We’ll explicitly gate on feature detection and present actionable errors.

- Model Artifacts (MLC-style packaging)
  - Library: `stable_diffusion_webgpu.wasm` (SD 1.5) and `stable_diffusion_xl.wasm` (SDXL).
  - Parameters: tvmjs NDArray cache shards (e.g., `web-sd-shards-v1-5/`, `web-sd-shards-xl/`) with metadata for param sizes per submodule.
  - Schedulers: JSON constants loaded at runtime.

## Build and Tooling

- Python packaging
  - `web_stable_diffusion/build.py` drives compile: Relax transforms, MetaSchedule database, and `export_library` to `.wasm` for target `webgpu`.
  - `tvm.contrib.tvmjs` used to dump/load NDArray parameter caches.

- Emscripten
  - Used by TVM to produce the WebAssembly runtime artifacts consumed by tvmjs.

- Node.js toolchain
  - For bundling/minifying JS assets when needed and for e2e testing tooling.

## Integration Surfaces

- Python → TVM
  - Capture: TorchDynamo/FX → TVM Relax via `relax.frontend`.
  - Transforms: `relax.pipeline.get_pipeline()`, DCE, `LiftTransformParams`, `BundleModelParams`.
  - Build: `relax.build(target="webgpu")` + MetaSchedule database application.
  - Output: `.wasm` plus parameter shards and scheduler JSON.

- Browser (JS) → tvmjs
  - Initialize: fetch `.wasm`, instantiate tvmjs with WASI shims, detect WebGPU device, `tvm.initWebGPU`.
  - Create VM: `tvm.createVirtualMachine(device)` then `vm.getFunction(...)` to retrieve compiled entrypoints.
  - Params: `tvm.fetchNDArrayCache(url, tvm.webgpu())` + `tvm.getParamsFromCache(name, size)`.
  - Inference loop: Run CLIP → UNet with scheduler steps → VAE → RGBA → draw to canvas.

## Constraints and Compatibility

- Python versioning
  - The project will target Python 3.13; pin to Python 3.13 for the compile pipeline to remain compatible with PyTorch 2.7. This decision is captured in Project Requirements and Sprint 0 exit criteria.

- TVM v0.21 web/runtime deltas
  - FFI changes and web runtime upgrade require building tvmjs artifacts from TVM v0.21 sources and validating our JS integration points continue to match public APIs noted above.

- Browser/WebGPU
  - Feature detect at runtime, present clear fallback messages, and avoid brittle user-agent checks.

## Security and Delivery

- Static hosting of artifacts (`/web/dist/*`, parameter shards) with integrity checks (content hashing/SRI where applicable).
- CORS-safe fetches for tokenizer JSON and parameter shards.
- No remote code execution paths; strictly data (weights/consts) loading.

## Observability

- Lightweight console logger and progress callbacks during initialization and inference steps.

## References

- Apache TVM v0.21.0 Release Notes: [link](https://github.com/apache/tvm/releases/tag/v0.21.0)
